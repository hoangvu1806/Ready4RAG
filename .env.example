# =============================================================================
# RAG Ingestion Pipeline - Environment Configuration
# Copy this file to .env and fill in your actual values.
# =============================================================================


# =============================================================================
# LLM PROVIDER FOR PDF-TO-MARKDOWN CONVERSION (Vision-capable model required)
# Options: openai | gemini | groq | ollama
# =============================================================================

PDF2MD_LLM_PROVIDER=gemini


# =============================================================================
# OPENAI
# =============================================================================

OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1

# Vision model for pdf2md; general model for entity extraction
OPENAI_VISION_MODEL=gpt-4o-mini
OPENAI_LLM_MODEL=gpt-4o-mini

# Embedding model: text-embedding-3-small (1536 dim) | text-embedding-3-large (3072 dim)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small


# =============================================================================
# GOOGLE GEMINI
# =============================================================================

GEMINI_API_KEY=

# Vision + LLM model for both pdf2md and entity extraction
GEMINI_MODEL=gemini-2.5-flash

# Embedding model: gemini-embedding-001 (3072 dim, supports MRL truncation to 768/1536/3072)
GEMINI_EMBEDDING_MODEL=gemini-embedding-001


# =============================================================================
# GROQ
# =============================================================================

GROQ_API_KEY=

# Vision model for pdf2md (multimodal)
GROQ_VISION_MODEL=meta-llama/llama-4-scout-17b-16e-instruct

# Text LLM for entity extraction
GROQ_LLM_MODEL=llama-3.3-70b-versatile


# =============================================================================
# OLLAMA (local)
# =============================================================================

OLLAMA_HOST=http://127.0.0.1:11434

# Vision model for pdf2md
OLLAMA_VISION_MODEL=llava

# Text model for entity extraction
OLLAMA_LLM_MODEL=llama3.2


# =============================================================================
# EMBEDDING PROVIDER FOR RAG INGESTION
# Options: openai | gemini | local
# =============================================================================

EMBEDDING_PROVIDER=gemini

# Override embedding dimension if using a non-standard model size
# Gemini gemini-embedding-001 default: 3072
# OpenAI text-embedding-3-small default: 1536
EMBEDDING_DIM=3072
EMBEDDING_BATCH_SIZE=32

# Local sentence-transformers model (used when EMBEDDING_PROVIDER=local)
LOCAL_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2


# =============================================================================
# LLM PROVIDER FOR RAG ENTITY EXTRACTION
# Options: openai | gemini | groq
# =============================================================================

LLM_PROVIDER=gemini
LLM_MAX_TOKENS=4096
LLM_TEMPERATURE=0.0


# =============================================================================
# VECTOR DATABASE (Qdrant)
# Set QDRANT_USE_LOCAL=true to use an embedded local file-based instance.
# Set QDRANT_USE_LOCAL=false to connect to a remote Qdrant server.
# =============================================================================

QDRANT_USE_LOCAL=true
QDRANT_PATH=./database/vector

# Remote Qdrant server (used when QDRANT_USE_LOCAL=false)
QDRANT_HOST=localhost
QDRANT_PORT=6333


# =============================================================================
# GRAPH DATABASE (NetworkX + GraphML file)
# =============================================================================

GRAPH_STORAGE_PATH=./database/graph


# =============================================================================
# PDF-TO-MARKDOWN OUTPUT
# =============================================================================

PDF2MD_OUTPUT_DIR=./output/markdown
PDF2MD_IMAGE_SIZE=1024
PDF2MD_PRESERVE_FORMULAS=true
PDF2MD_EXTRACT_IMAGES=false
PDF2MD_MAX_WORKERS=4


# =============================================================================
# RAG INGESTION PIPELINE
# =============================================================================

RAG_INPUT_DIR=./output/markdown
RAG_MAX_WORKERS=4
RAG_ENABLE_ENTITY_EXTRACTION=true
RAG_ENABLE_RELATIONSHIP_EXTRACTION=true
RAG_ENABLE_SUMMARY=true


# =============================================================================
# CHUNKING STRATEGY
# =============================================================================

CHUNK_BY_PAGE=true
CHUNK_SIZE=512
CHUNK_OVERLAP=64
MIN_CHUNK_SIZE=100
